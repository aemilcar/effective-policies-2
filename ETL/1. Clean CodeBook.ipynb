{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    data = []\n",
    "    f = '../Data/codebook_21.txt'\n",
    "    with open(f) as f_pointer:\n",
    "        for row in f_pointer.readlines():\n",
    "            data.append(row.strip('/n'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on eyeballing the codebook, it looks like all of our data is a numerical format. Let's try to read everything into a nest of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def is_int(row, meta_heading):\n",
    "#     if meta_heading == 'FARM':\n",
    "#         print (row)\n",
    "\n",
    "    try:\n",
    "        int(row[0])\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "      \n",
    "def is_metaheading(row):\n",
    "    if '\\t' in row and row[0].isalpha():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def is_subheader(row, meta_heading):\n",
    "    \n",
    "    # these are meta headings where the keys have tabs\n",
    "    # this throws off the logic below, but b/c we know from the codebook that they have no subheadings\n",
    "    # we automatically return False\n",
    "    if meta_heading in ['FARM','UNITSSTR', 'RELATE', 'RELATED', 'WKSWORK2', 'MULTGEND', 'METRO',\n",
    "                        'WORKEDYR', 'SCHLTYPE', 'VETVIETN', 'EMPSTATD', 'MIGRATE1D', 'LANGUAGE',\n",
    "                       'GQ', 'MIGPLAC1']:\n",
    "        return False\n",
    "\n",
    "    a = row[0].isalpha()\n",
    "    b = '\\t' not in row\n",
    "    c = ('-' in row) or (':' in row)\n",
    "    \n",
    "    rt = (a and b) or c\n",
    "\n",
    "    \n",
    "    return rt\n",
    "\n",
    "def is_header_break(row):\n",
    "    return row == '\\n'\n",
    "\n",
    "# This skips subheadings right now by a list\n",
    "# But are there any subheadings that we want stored in the old way right now? Unknown. \n",
    "def create_codebook_store(data):\n",
    "    store = {}\n",
    "    \n",
    "    sub_headings_direct = ['REGION', 'GQ', 'ACREHOUS', 'BPL']\n",
    "    has_subheading = False\n",
    "    sub_heading_direct_placement = False\n",
    "    \n",
    "    for idx, row in enumerate(data):\n",
    "        \n",
    "        # find the meta heading and create that dictionary \n",
    "        if is_metaheading(row):\n",
    "            meta_heading = row.split('\\t') [0]\n",
    "            meta_dict = {}\n",
    "            has_subheading = False\n",
    "\n",
    "            if meta_heading in sub_headings_direct:\n",
    "                sub_heading_direct_placement = True\n",
    "            continue\n",
    "\n",
    "\n",
    "        # find the sub headings and create inner dictionaries\n",
    "        elif is_subheader(row, meta_heading):\n",
    "\n",
    "            sub_heading = row.strip('\\n')\n",
    "            \n",
    "            has_subheading = True\n",
    "\n",
    "            if not sub_heading_direct_placement:\n",
    "                meta_dict[sub_heading] = {}\n",
    "                \n",
    "            continue\n",
    "\n",
    "        # find the integers and add them, along with their meanings, to the inner dictionary\n",
    "        elif is_int(row, meta_heading):\n",
    "            \n",
    "            lines = row.split('\\t')\n",
    "            key = int(lines[0].strip('/t'))\n",
    "            value = lines[-1].strip('\\n')\n",
    "            \n",
    "            if has_subheading and not sub_heading_direct_placement:\n",
    "                meta_dict[sub_heading][key] = value\n",
    "            \n",
    "            elif has_subheading and sub_heading_direct_placement:\n",
    "                meta_dict[key] = sub_heading\n",
    "            \n",
    "            else:\n",
    "                meta_dict[key] = value\n",
    "            \n",
    "            continue\n",
    "\n",
    "        # find the header break\n",
    "        elif is_header_break(row):\n",
    "            store[meta_heading] = meta_dict\n",
    "            has_subheading = False\n",
    "            skip_subheading = False\n",
    " \n",
    "    return store \n",
    "\n",
    "data = read_data()\n",
    "store = create_codebook_store(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_store_to_disk(d, f_name):\n",
    "    j_file = json.dumps(d)\n",
    "    f = open(f_name, \"w\")\n",
    "    f.write(j_file)\n",
    "    f.close()\n",
    "\n",
    "write_store_to_disk(store, '../Data/codebook.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'Alabama',\n",
       " 2: 'Alaska',\n",
       " 4: 'Arizona',\n",
       " 5: 'Arkansas',\n",
       " 6: 'California',\n",
       " 8: 'Colorado',\n",
       " 9: 'Connecticut',\n",
       " 10: 'Delaware',\n",
       " 11: 'District of Columbia',\n",
       " 12: 'Florida',\n",
       " 13: 'Georgia',\n",
       " 15: 'Hawaii',\n",
       " 16: 'Idaho',\n",
       " 17: 'Illinois',\n",
       " 18: 'Indiana',\n",
       " 19: 'Iowa',\n",
       " 20: 'Kansas',\n",
       " 21: 'Kentucky',\n",
       " 22: 'Louisiana',\n",
       " 23: 'Maine',\n",
       " 24: 'Maryland',\n",
       " 25: 'Massachusetts',\n",
       " 26: 'Michigan',\n",
       " 27: 'Minnesota',\n",
       " 28: 'Mississippi',\n",
       " 29: 'Missouri',\n",
       " 30: 'Montana',\n",
       " 31: 'Nebraska',\n",
       " 32: 'Nevada',\n",
       " 33: 'New Hampshire',\n",
       " 34: 'New Jersey',\n",
       " 35: 'New Mexico',\n",
       " 36: 'New York',\n",
       " 37: 'North Carolina',\n",
       " 38: 'North Dakota',\n",
       " 39: 'Ohio',\n",
       " 40: 'Oklahoma',\n",
       " 41: 'Oregon',\n",
       " 42: 'Pennsylvania',\n",
       " 44: 'Rhode Island',\n",
       " 45: 'South Carolina',\n",
       " 46: 'South Dakota',\n",
       " 47: 'Tennessee',\n",
       " 48: 'Texas',\n",
       " 49: 'Utah',\n",
       " 50: 'Vermont',\n",
       " 51: 'Virginia',\n",
       " 53: 'Washington',\n",
       " 54: 'West Virginia',\n",
       " 55: 'Wisconsin',\n",
       " 56: 'Wyoming',\n",
       " 90: 'Native American',\n",
       " 99: 'United States, ns',\n",
       " 100: 'American Samoa',\n",
       " 105: 'Guam',\n",
       " 110: 'Puerto Rico',\n",
       " 115: 'U.S. Virgin Islands',\n",
       " 120: 'Other US Possessions',\n",
       " 150: 'OTHER NORTH AMERICA',\n",
       " 155: 'OTHER NORTH AMERICA',\n",
       " 160: 'OTHER NORTH AMERICA',\n",
       " 199: 'OTHER NORTH AMERICA',\n",
       " 200: 'CENTRAL AMERICA AND CARIBBEAN',\n",
       " 210: 'CENTRAL AMERICA AND CARIBBEAN',\n",
       " 250: 'Caribbean:',\n",
       " 260: 'Caribbean:',\n",
       " 299: 'Caribbean:',\n",
       " 300: 'Caribbean:',\n",
       " 400: 'Northern Europe:',\n",
       " 401: 'Northern Europe:',\n",
       " 402: 'Northern Europe:',\n",
       " 403: 'Northern Europe:',\n",
       " 404: 'Northern Europe:',\n",
       " 405: 'Northern Europe:',\n",
       " 410: 'United Kingdom and Ireland:',\n",
       " 411: 'United Kingdom and Ireland:',\n",
       " 412: 'United Kingdom and Ireland:',\n",
       " 413: 'United Kingdom and Ireland:',\n",
       " 414: 'United Kingdom and Ireland:',\n",
       " 419: 'United Kingdom and Ireland:',\n",
       " 420: 'Western Europe:',\n",
       " 421: 'Western Europe:',\n",
       " 422: 'Western Europe:',\n",
       " 423: 'Western Europe:',\n",
       " 424: 'Western Europe:',\n",
       " 425: 'Western Europe:',\n",
       " 426: 'Western Europe:',\n",
       " 429: 'Western Europe:',\n",
       " 430: 'Southern Europe:',\n",
       " 431: 'Southern Europe:',\n",
       " 432: 'Southern Europe:',\n",
       " 433: 'Southern Europe:',\n",
       " 434: 'Southern Europe:',\n",
       " 435: 'Southern Europe:',\n",
       " 436: 'Southern Europe:',\n",
       " 437: 'Southern Europe:',\n",
       " 438: 'Southern Europe:',\n",
       " 439: 'Southern Europe:',\n",
       " 440: 'Southern Europe:',\n",
       " 450: 'Central/Eastern Europe:',\n",
       " 451: 'Central/Eastern Europe:',\n",
       " 452: 'Central/Eastern Europe:',\n",
       " 453: 'Central/Eastern Europe:',\n",
       " 454: 'Central/Eastern Europe:',\n",
       " 455: 'Central/Eastern Europe:',\n",
       " 456: 'Central/Eastern Europe:',\n",
       " 457: 'Central/Eastern Europe:',\n",
       " 458: 'Central/Eastern Europe:',\n",
       " 459: 'Central/Eastern Europe:',\n",
       " 460: 'Russian Empire:',\n",
       " 461: 'Russian Empire:',\n",
       " 462: 'Russian Empire:',\n",
       " 463: 'Russian Empire:',\n",
       " 465: 'Russian Empire:',\n",
       " 499: 'Russian Empire:',\n",
       " 500: 'East Asia:',\n",
       " 501: 'East Asia:',\n",
       " 502: 'East Asia:',\n",
       " 509: 'East Asia:',\n",
       " 510: 'Southeast Asia:',\n",
       " 511: 'Southeast Asia:',\n",
       " 512: 'Southeast Asia:',\n",
       " 513: 'Southeast Asia:',\n",
       " 514: 'Southeast Asia:',\n",
       " 515: 'Southeast Asia:',\n",
       " 516: 'Southeast Asia:',\n",
       " 517: 'Southeast Asia:',\n",
       " 518: 'Southeast Asia:',\n",
       " 519: 'Southeast Asia:',\n",
       " 520: 'India/Southwest Asia:',\n",
       " 521: 'India/Southwest Asia:',\n",
       " 522: 'India/Southwest Asia:',\n",
       " 523: 'India/Southwest Asia:',\n",
       " 524: 'India/Southwest Asia:',\n",
       " 530: 'Middle East/Asia Minor:',\n",
       " 531: 'Middle East/Asia Minor:',\n",
       " 532: 'Middle East/Asia Minor:',\n",
       " 533: 'Middle East/Asia Minor:',\n",
       " 534: 'Middle East/Asia Minor:',\n",
       " 535: 'Middle East/Asia Minor:',\n",
       " 536: 'Middle East/Asia Minor:',\n",
       " 537: 'Middle East/Asia Minor:',\n",
       " 538: 'Middle East/Asia Minor:',\n",
       " 539: 'Middle East/Asia Minor:',\n",
       " 540: 'Middle East/Asia Minor:',\n",
       " 541: 'Middle East/Asia Minor:',\n",
       " 542: 'Middle East/Asia Minor:',\n",
       " 543: 'Middle East/Asia Minor:',\n",
       " 544: 'Middle East/Asia Minor:',\n",
       " 545: 'Middle East/Asia Minor:',\n",
       " 546: 'Middle East/Asia Minor:',\n",
       " 547: 'Middle East/Asia Minor:',\n",
       " 548: 'Middle East/Asia Minor:',\n",
       " 549: 'Middle East/Asia Minor:',\n",
       " 550: 'Middle East/Asia Minor:',\n",
       " 599: 'Middle East/Asia Minor:',\n",
       " 600: 'AFRICA',\n",
       " 700: 'OCEANIA',\n",
       " 710: 'OCEANIA',\n",
       " 800: 'OCEANIA',\n",
       " 900: 'OCEANIA',\n",
       " 950: 'OCEANIA',\n",
       " 999: 'OCEANIA'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This is tripping the is_subheading function, need to rectify \n",
    "store['BPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
