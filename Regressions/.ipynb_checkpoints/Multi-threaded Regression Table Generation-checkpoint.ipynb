{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "from scipy.stats import ttest_ind\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for regression table\n",
    "- Get meta distributions for each state in 2017\n",
    "- Store N*N state meta distribution comparison\n",
    "- Loop pairs through map/reduce\n",
    "- For each pair: do\n",
    "    - Run t-test\n",
    "    - Run regression\n",
    "    - Store t-test and regression results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset isn't the final one, because we still need to actually cast all of the numeric fields as numeric.\n",
    "\n",
    "I'm still going to use it, because we need to make progress on the regression table programming. Once we're closer to having clean data, we can come back and use this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (7,8,9,11,13,14,26,28,29,30,31,32,33,37,38,46,47,71) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "all_states = pd.read_csv('../../Data/transformed_missing_replaced_with_zero.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_states.drop(['PERWT', 'YRIMMIG'] , axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = list(set((all_states['STATEICP'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs():\n",
    "    rt = {}\n",
    "    \n",
    "    for idx, s in enumerate(states):\n",
    "\n",
    "        to_iterate = states[idx+1:]\n",
    "\n",
    "        for j in to_iterate:\n",
    "\n",
    "            if s[0] < j[0]:\n",
    "                string = '{}-{}'.format(s,j)\n",
    "            else:\n",
    "                string = '{}-{}'.format(j,s)\n",
    "\n",
    "            if string not in rt:\n",
    "                rt[string] = {}\n",
    "    \n",
    "    return rt\n",
    "\n",
    "pairs = get_pairs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = list(all_states.select_dtypes(include=[np.number]))\n",
    "numerics.append('STATEICP')\n",
    "df = all_states[ numerics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distributions(states, df):\n",
    "    '''\n",
    "    Returns a dictionary with the state averages on all columns, for each state\n",
    "    '''\n",
    "    rt = {}\n",
    "\n",
    "    for s in states:\n",
    "        \n",
    "        meta = []\n",
    "        \n",
    "        state_df = df[ df['STATEICP'] == s]\n",
    "        \n",
    "        for h in list(state_df):\n",
    "            if h == 'STATEICP':\n",
    "                continue\n",
    "            mean = state_df[h].mean()\n",
    "            meta.append(mean)\n",
    "        \n",
    "        rt[s] = meta\n",
    "    return rt\n",
    "        \n",
    "distributions = get_distributions(states, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regression(s1, s2):\n",
    "    \n",
    "    OUTCOME_COL = 'POVERTY'\n",
    "    \n",
    "    reg_data = df[ df['STATEICP'].isin([s1,s2])]\n",
    "    \n",
    "    reg_data = pd.get_dummies(reg_data, columns = ['STATEICP']).drop('YEAR', axis=1,inplace=False)\n",
    "        \n",
    "    ys = reg_data[OUTCOME_COL]\n",
    "    \n",
    "    xs = reg_data.drop(OUTCOME_COL, inplace=False, axis=1)\n",
    "\n",
    "    sm.add_constant(xs)\n",
    "    model = sm.OLS(ys, xs).fit()\n",
    "\n",
    "    s = str(model.summary())\n",
    "    \n",
    "    splits = s.split('STATEICP')[1].split(' ')\n",
    "    \n",
    "    cleaned_splits = [i for i in splits if '.' in i]\n",
    "\n",
    "    treatment_beta = cleaned_splits[0]\n",
    "    t_value = cleaned_splits[2]\n",
    "    return [s1, s2, treatment_beta, t_value]\n",
    "\n",
    "effect = transform_pair('Arizona-New Jersey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arizona', 'New Jersey', '583.0883', '13.507']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_pair(string):\n",
    "    significance_level = 0.05\n",
    "    \n",
    "    # get distributions for both states\n",
    "    splits = string.split('-')\n",
    "    s1, s2 = splits[0], splits[1]\n",
    "    dist1 = distributions[s1]\n",
    "    dist2 = distributions[s2]\n",
    "    \n",
    "    # run t-test\n",
    "    sim_t, p_value = ttest_ind(dist1, dist2)\n",
    "    \n",
    "    # Need to add some logic here for evaluating policy levers. \n",
    "    # Ideally, only one lever is different, and this is the one that they are about to enact \n",
    "    \n",
    "    # if les than .05, fail to reject null hypothesis and conclude difference. Otherwise, they're similar\n",
    "    if p_value < significance_level:\n",
    "        print ('Cannot run an RCT at this level of similarity')\n",
    "        return []\n",
    "    \n",
    "    effect = run_regression(s1, s2)\n",
    "    effect.append(sim_t)\n",
    "    \n",
    "    return effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_regressions():\n",
    "\n",
    "    pool = Pool(processes=multiprocessing.cpu_count())\n",
    "\n",
    "    regressions = pool.map(transform_pair, list(pairs.keys()))\n",
    "    pool.close() \n",
    "    pool.join()    \n",
    "    \n",
    "    return regressions\n",
    "\n",
    "regressions = run_regressions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df = pd.DataFrame(regressions, columns = ['Treatment State', 'Control 2', 'Treatment Beta', 'Treatment T Value', 'Similarity T Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_df.to_csv('../../Data/regression_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 68.9 KiB/68.9 KiB (631.0 KiB/s) with 1 file(s) remaining\r",
      "upload: ../../Data/regression_table.csv to s3://ep-agent/regression_table.csv\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp '../../Data/regression_table.csv' s3://ep-agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
